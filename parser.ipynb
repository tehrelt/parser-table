{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "realms = ['scourge_x2', 'legacy_x3', 'algalon_x4', 'sirus_x5', 'legacy_x10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(page : int):\n",
    "    return f'https://sirus.su/statistic/online?page={page}#/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 353\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) Gecko/20100101 Firefox/102.0'\n",
    "}\n",
    "\n",
    "response = requests.get(get_url(1), headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "count_of_pages = int(soup.find('ul', attrs={'class': 'pagination'}).find_all('li')[-2].text)\n",
    "print(f'Pages: {count_of_pages}')\n",
    "\n",
    "for i in range(count_of_pages):\n",
    "    # time.sleep(1)\n",
    "    if not os.path.exists(f'pages/index_page{i+1}.html'):\n",
    "        response = requests.get(get_url(i+1), headers=headers)\n",
    "        print(f'Downloaded page {i+1}')\n",
    "        with open(f'pages/index_page{i+1}.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание Базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE scourge_x2\n",
      "CREATE TABLE legacy_x3\n",
      "CREATE TABLE algalon_x4\n",
      "CREATE TABLE sirus_x5\n",
      "CREATE TABLE legacy_x10\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "with sqlite3.connect('players.db') as db:\n",
    "    cursor = db.cursor() \n",
    "    \n",
    "    for realm in realms:\n",
    "        print(f\"\"\"CREATE TABLE {realm}\"\"\")\n",
    "        cursor.execute(f\"\"\"DELETE FROM {realm}\"\"\")\n",
    "        cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {realm}\n",
    "                   (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                   name TEXT,\n",
    "                   level INTEGER,\n",
    "                   class TEXT,\n",
    "                   race TEXT)\n",
    "                   \"\"\")\n",
    "    db.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(data, table_name):\n",
    "    with sqlite3.connect('players.db') as db:\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(f\"\"\"INSERT INTO {table_name} (name, level, race, class) VALUES (?, ?, ?, ?)\"\"\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message, file='log.log'):\n",
    "    with open(file, 'a', encoding='utf-8') as log:\n",
    "        log.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page #1\n",
      "Page #2\n",
      "Page #3\n",
      "Page #4\n",
      "Page #5\n",
      "Page #6\n",
      "Page #7\n",
      "Page #8\n",
      "Page #9\n",
      "Page #10\n",
      "Page #11\n",
      "Page #12\n",
      "Page #13\n",
      "Page #14\n",
      "Page #15\n",
      "Page #16\n",
      "Page #17\n",
      "Page #18\n",
      "Page #19\n",
      "Page #20\n",
      "Page #21\n",
      "Page #22\n",
      "Page #23\n",
      "Page #24\n",
      "Page #25\n",
      "Page #26\n",
      "Page #27\n",
      "Page #28\n",
      "Page #29\n",
      "Page #30\n",
      "Page #31\n",
      "Page #32\n",
      "Page #33\n",
      "Page #34\n",
      "Page #35\n",
      "Page #36\n",
      "Page #37\n",
      "Page #38\n",
      "Page #39\n",
      "Page #40\n",
      "Page #41\n",
      "Page #42\n",
      "Page #43\n",
      "Page #44\n",
      "Page #45\n",
      "Page #46\n",
      "Page #47\n",
      "Page #48\n",
      "Page #49\n",
      "Page #50\n",
      "Page #51\n",
      "Page #52\n",
      "Page #53\n",
      "Page #54\n",
      "Page #55\n",
      "Page #56\n",
      "Page #57\n",
      "Page #58\n",
      "Page #59\n",
      "Page #60\n",
      "Page #61\n",
      "Page #62\n",
      "Page #63\n",
      "Page #64\n",
      "Page #65\n",
      "Page #66\n",
      "Page #67\n",
      "Page #68\n",
      "Page #69\n",
      "Page #70\n",
      "Page #71\n",
      "Page #72\n",
      "Page #73\n",
      "Page #74\n",
      "Page #75\n",
      "Page #76\n",
      "Page #77\n",
      "Page #78\n",
      "Page #79\n",
      "Page #80\n",
      "Page #81\n",
      "Page #82\n",
      "Page #83\n",
      "Page #84\n",
      "Page #85\n",
      "Page #86\n",
      "Page #87\n",
      "Page #88\n",
      "Page #89\n",
      "Page #90\n",
      "Page #91\n",
      "Page #92\n",
      "Page #93\n",
      "Page #94\n",
      "Page #95\n",
      "Page #96\n",
      "Page #97\n",
      "Page #98\n",
      "Page #99\n",
      "Page #100\n",
      "Page #101\n",
      "Page #102\n",
      "Page #103\n",
      "Page #104\n",
      "Page #105\n",
      "Page #106\n",
      "Page #107\n",
      "Page #108\n",
      "Page #109\n",
      "Page #110\n",
      "Page #111\n",
      "Page #112\n",
      "Page #113\n",
      "Page #114\n",
      "Page #115\n",
      "Page #116\n",
      "Page #117\n",
      "Page #118\n",
      "Page #119\n",
      "Page #120\n",
      "Page #121\n",
      "Page #122\n",
      "Page #123\n",
      "Page #124\n",
      "Page #125\n",
      "Page #126\n",
      "Page #127\n",
      "Page #128\n",
      "Page #129\n",
      "Page #130\n",
      "Page #131\n",
      "Page #132\n",
      "Page #133\n",
      "Page #134\n",
      "Page #135\n",
      "Page #136\n",
      "Page #137\n",
      "Page #138\n",
      "Page #139\n",
      "Page #140\n",
      "Page #141\n",
      "Page #142\n",
      "Page #143\n",
      "Page #144\n",
      "Page #145\n",
      "Page #146\n",
      "Page #147\n",
      "Page #148\n",
      "Page #149\n",
      "Page #150\n",
      "Page #151\n",
      "Page #152\n",
      "Page #153\n",
      "Page #154\n",
      "Page #155\n",
      "Page #156\n",
      "Page #157\n",
      "Page #158\n",
      "Page #159\n",
      "Page #160\n",
      "Page #161\n",
      "Page #162\n",
      "Page #163\n",
      "Page #164\n",
      "Page #165\n",
      "Page #166\n",
      "Page #167\n",
      "Page #168\n",
      "Page #169\n",
      "Page #170\n",
      "Page #171\n",
      "Page #172\n",
      "Page #173\n",
      "Page #174\n",
      "Page #175\n",
      "Page #176\n",
      "Page #177\n",
      "Page #178\n",
      "Page #179\n",
      "Page #180\n",
      "Page #181\n",
      "Page #182\n",
      "Page #183\n",
      "Page #184\n",
      "Page #185\n",
      "Page #186\n",
      "Page #187\n",
      "Page #188\n",
      "Page #189\n",
      "Page #190\n",
      "Page #191\n",
      "Page #192\n",
      "Page #193\n",
      "Page #194\n",
      "Page #195\n",
      "Page #196\n",
      "Page #197\n",
      "Page #198\n",
      "Page #199\n",
      "Page #200\n",
      "Page #201\n",
      "Page #202\n",
      "Page #203\n",
      "Page #204\n",
      "Page #205\n",
      "Page #206\n",
      "Page #207\n",
      "Page #208\n",
      "Page #209\n",
      "Page #210\n",
      "Page #211\n",
      "Page #212\n",
      "Page #213\n",
      "Page #214\n",
      "Page #215\n",
      "Page #216\n",
      "Page #217\n",
      "Page #218\n",
      "Page #219\n",
      "Page #220\n",
      "Page #221\n",
      "Page #222\n",
      "Page #223\n",
      "Page #224\n",
      "Page #225\n",
      "Page #226\n",
      "Page #227\n",
      "Page #228\n",
      "Page #229\n",
      "Page #230\n",
      "Page #231\n",
      "Page #232\n",
      "Page #233\n",
      "Page #234\n",
      "Page #235\n",
      "Page #236\n",
      "Page #237\n",
      "Page #238\n",
      "Page #239\n",
      "Page #240\n",
      "Page #241\n",
      "Page #242\n",
      "Page #243\n",
      "Page #244\n",
      "Page #245\n",
      "Page #246\n",
      "Page #247\n",
      "Page #248\n",
      "Page #249\n",
      "Page #250\n",
      "Page #251\n",
      "Page #252\n",
      "Page #253\n",
      "Page #254\n",
      "Page #255\n",
      "Page #256\n",
      "Page #257\n",
      "Page #258\n",
      "Page #259\n",
      "Page #260\n",
      "Page #261\n",
      "Page #262\n",
      "Page #263\n",
      "Page #264\n",
      "Page #265\n",
      "Page #266\n",
      "Page #267\n",
      "Page #268\n",
      "Page #269\n",
      "Page #270\n",
      "Page #271\n",
      "Page #272\n",
      "Page #273\n",
      "Page #274\n",
      "Page #275\n",
      "Page #276\n",
      "Page #277\n",
      "Page #278\n",
      "Page #279\n",
      "Page #280\n",
      "Page #281\n",
      "Page #282\n",
      "Page #283\n",
      "Page #284\n",
      "Page #285\n",
      "Page #286\n",
      "Page #287\n",
      "Page #288\n",
      "Page #289\n",
      "Page #290\n",
      "Page #291\n",
      "Page #292\n",
      "Page #293\n",
      "Page #294\n",
      "Page #295\n",
      "Page #296\n",
      "Page #297\n",
      "Page #298\n",
      "Page #299\n",
      "Page #300\n",
      "Page #301\n",
      "Page #302\n",
      "Page #303\n",
      "Page #304\n",
      "Page #305\n",
      "Page #306\n",
      "Page #307\n",
      "Page #308\n",
      "Page #309\n",
      "Page #310\n",
      "Page #311\n",
      "Page #312\n",
      "Page #313\n",
      "Page #314\n",
      "Page #315\n",
      "Page #316\n",
      "Page #317\n",
      "Page #318\n",
      "Page #319\n",
      "Page #320\n",
      "Page #321\n",
      "Page #322\n",
      "Page #323\n",
      "Page #324\n",
      "Page #325\n",
      "Page #326\n",
      "Page #327\n",
      "Page #328\n",
      "Page #329\n",
      "Page #330\n",
      "Page #331\n",
      "Page #332\n",
      "Page #333\n",
      "Page #334\n",
      "Page #335\n",
      "Page #336\n",
      "Page #337\n",
      "Page #338\n",
      "Page #339\n",
      "Page #340\n",
      "Page #341\n",
      "Page #342\n",
      "Page #343\n",
      "Page #344\n",
      "Page #345\n",
      "Page #346\n",
      "Page #347\n",
      "Page #348\n",
      "Page #349\n",
      "Page #350\n",
      "Page #351\n",
      "Page #352\n",
      "Page #353\n",
      "['scourge_x2', 'legacy_x3', 'algalon_x4', 'sirus_x5', 'legacy_x10']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "played_id = 0\n",
    "for i in range(count_of_pages):\n",
    "    print(f'Page {i+1}/{count_of_pages}')\n",
    "    try:\n",
    "        with open(f'pages/index_page{i+1}.html', 'r', encoding='utf-8') as f:\n",
    "            html = f.read()\n",
    "    except Exception as e: \n",
    "        print('with exception', e)\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    table = soup.find('table')\n",
    "\n",
    "    trs = soup.find_all('tr')\n",
    "    with sqlite3.connect('players.db') as db:\n",
    "        cursor = db.cursor()\n",
    "        for i, tr in enumerate(trs):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            tds = tr.find_all('td')\n",
    "            name = tds[0].text.replace('\\n', '').strip()\n",
    "            level = tds[1].text.replace('\\n', '').strip()\n",
    "            race = tds[2].find('img', class_='race').get('title')\n",
    "            class_ = tds[2].find('img', class_='class').get('title')\n",
    "            realm = tds[3].text.replace('\\n', '').strip().split(\"-\")[0].lower().strip().replace(\" \", \"_\")        \n",
    "            \n",
    "            log(\n",
    "                message=f'#{played_id} {name} {level} {race} {class_} - {realm}', \n",
    "                file=f'logs/log_{realm}.log'\n",
    "            )\n",
    "            insert_data((name, level, race, class_), table_name=realm)\n",
    "                \n",
    "            played_id += 1\n",
    "            \n",
    "print(realms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE scourge_x2\n",
      "TABLE legacy_x3\n",
      "TABLE algalon_x4\n",
      "TABLE sirus_x5\n",
      "TABLE legacy_x10\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def print_table(table_name):\n",
    "    with sqlite3.connect('players.db') as db:\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(f\"\"\"SELECT * FROM {table_name}\"\"\")\n",
    "        table = prettytable.from_db_cursor(cursor=cursor)\n",
    "    with open(f'tables/{table_name}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(str(table))\n",
    "    # print(table)\n",
    "def print_json(table_name):\n",
    "    with open(f'json/{table_name}.json', 'w', encoding='utf-8') as j:\n",
    "        with sqlite3.connect('players.db') as db:\n",
    "            cursor = db.cursor()\n",
    "            cursor.execute(f\"\"\"SELECT name, level, class, race FROM {table_name}\"\"\")\n",
    "            json.dump(cursor.fetchall(), j, indent=4, ensure_ascii=False)\n",
    "\n",
    "def print_csv(table_name):\n",
    "    with open(f'csv/{table_name}.csv', 'w', encoding='utf-8', newline='') as c:\n",
    "        with sqlite3.connect('players.db') as db:\n",
    "            cursor = db.cursor()\n",
    "            cursor.execute(f\"\"\"SELECT * FROM {table_name}\"\"\")\n",
    "            writer = csv.writer(c, delimiter=';')\n",
    "            \n",
    "            writer.writerow\n",
    "            (\n",
    "                ('ID', 'Ник', 'Уровень', 'Раса', 'Класс')\n",
    "            )\n",
    "            \n",
    "            writer.writerows(cursor.fetchall())\n",
    "\n",
    "for realm in realms:\n",
    "    print(f'TABLE {realm}')\n",
    "    print_table(realm)\n",
    "    print_json(realm)\n",
    "    print_csv(realm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec37068f460b6b7cc8f9068c2cafbf94f5660ee969607ff2f440e4a9ddfd9795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
